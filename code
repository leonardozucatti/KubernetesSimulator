import threading
import queue
import time

# Definição da classe Pod que representa as unidades de trabalho a serem alocadas nos Workers
class Pod:
    def __init__(self, pod_id, cpu, memory, disk):
        self.pod_id = pod_id
        self.cpu = cpu
        self.memory = memory
        self.disk = disk

# Definição da classe Worker que representa os nodos Workers do cluster Kubernetes
class Worker:
    def __init__(self, worker_id, cpu_capacity, memory_capacity, network_latency, disk_capacity, work_queue):
        # Identificador único do Worker
        self.worker_id = worker_id
        # Capacidades do Worker
        self.cpu_capacity = cpu_capacity
        self.memory_capacity = memory_capacity
        self.network_latency = network_latency
        self.disk_capacity = disk_capacity
        # Recursos atualmente em uso pelo Worker
        self.cpu_usage = 0
        self.memory_usage = 0
        self.disk_usage = 0
        # Lista de PODs alocados no Worker
        self.pods = []
        # Fila de trabalho compartilhada com o Master
        self.work_queue = work_queue

    # Método para alocar recursos para um novo POD
    def allocate_resources(self, pod):
        if (self.cpu_usage + pod.cpu <= self.cpu_capacity and
                self.memory_usage + pod.memory <= self.memory_capacity and
                self.disk_usage + pod.disk <= self.disk_capacity):
            # Alocar recursos
            self.cpu_usage += pod.cpu
            self.memory_usage += pod.memory
            self.disk_usage += pod.disk
            self.pods.append(pod)
            print(f"POD {pod.pod_id} alocado no Worker {self.worker_id}")
            return True
        else:
            print(f"POD {pod.pod_id} não pode ser alocado no Worker {self.worker_id}")
            return False

    # Método para simular o processamento contínuo de tarefas no Worker
    def process_tasks(self):
        while True:
            time.sleep(5)  # Simula o tempo de processamento de tarefas

            if self.pods:
                completed_pod = self.pods[0]
                print(f"Tarefas concluídas para POD {completed_pod.pod_id} no Worker {self.worker_id}")
                self.cpu_usage -= completed_pod.cpu
                self.memory_usage -= completed_pod.memory
                self.disk_usage -= completed_pod.disk
                self.pods.pop(0)  # Remove o POD concluído
                self.print_status()  # Imprime o status atual do Worker

                # Adiciona um novo POD à fila para ser processado
                new_pod = Pod(pod_id=completed_pod.pod_id + 100, cpu=2, memory=200, disk=50)
                self.work_queue.put(new_pod)
                print(f"Novo POD {new_pod.pod_id} adicionado à fila para processamento no Worker {self.worker_id}")

    # Método para imprimir o status atual do Worker
    def print_status(self):
        print(f"Worker {self.worker_id} - CPU: {self.cpu_usage}/{self.cpu_capacity}, "
              f"Memory: {self.memory_usage}/{self.memory_capacity}, "
              f"Disk: {self.disk_usage}/{self.disk_capacity}, "
              f"Pods: {len(self.pods)}")

# Definição da classe Master que coordena a alocação de PODs nos Workers
class Master:
    def __init__(self, workers):
        self.workers = workers

    # Método para agendar a alocação de PODs nos Workers
    def schedule_pods(self, pod_queue):
        while True:
            pod = pod_queue.get()
            if pod is None:
                break  # Encerra a execução ao receber um marcador de encerramento
            allocated = False
            for worker in self.workers:
                if worker.allocate_resources(pod):
                    allocated = True
                    break
            if not allocated:
                print(f"POD {pod.pod_id} não pôde ser alocado em nenhum Worker")
            self.print_cluster_status()
            time.sleep(0.5)

    # Método para imprimir o status atual do cluster
    def print_cluster_status(self):
        print("\nStatus do Cluster:")
        for worker in self.workers:
            worker.print_status()

# Função que simula a produção contínua de PODs
def producer(queue):
    i = 0
    while True:
        pod = Pod(pod_id=i, cpu=i % 3 + 1, memory=(i % 3 + 1) * 100, disk=50)
        queue.put(pod)
        print(f"POD {pod.pod_id} criado e adicionado à fila")
        time.sleep(1)
        i += 1

# Função principal
def main():
    num_workers = 2
    work_queue = queue.Queue()
    # Criação de Workers com capacidades específicas
    workers = [Worker(i, cpu_capacity=5, memory_capacity=500, network_latency=2, disk_capacity=200, work_queue=work_queue) for i in range(num_workers)]
    master = Master(workers)

    producer_thread = threading.Thread(target=producer, args=(work_queue,))
    consumer_thread = threading.Thread(target=master.schedule_pods, args=(work_queue,))
    processing_threads = [threading.Thread(target=worker.process_tasks) for worker in workers]

    producer_thread.start()
    consumer_thread.start()
    for thread in processing_threads:
        thread.start()

    input("Pressione Enter para encerrar...")

    work_queue.put(None)
    producer_thread.join()
    consumer_thread.join()

    for worker in workers:
        work_queue.put(None)

    for thread in processing_threads:
        thread.join()

if __name__ == "__main__":
    main()import threading
import queue
import time

# Definição da classe Pod que representa as unidades de trabalho a serem alocadas nos Workers
class Pod:
    def __init__(self, pod_id, cpu, memory, disk):
        self.pod_id = pod_id
        self.cpu = cpu
        self.memory = memory
        self.disk = disk

# Definição da classe Worker que representa os nodos Workers do cluster Kubernetes
class Worker:
    def __init__(self, worker_id, cpu_capacity, memory_capacity, network_latency, disk_capacity, work_queue):
        # Identificador único do Worker
        self.worker_id = worker_id
        # Capacidades do Worker
        self.cpu_capacity = cpu_capacity
        self.memory_capacity = memory_capacity
        self.network_latency = network_latency
        self.disk_capacity = disk_capacity
        # Recursos atualmente em uso pelo Worker
        self.cpu_usage = 0
        self.memory_usage = 0
        self.disk_usage = 0
        # Lista de PODs alocados no Worker
        self.pods = []
        # Fila de trabalho compartilhada com o Master
        self.work_queue = work_queue

    # Método para alocar recursos para um novo POD
    def allocate_resources(self, pod):
        if (self.cpu_usage + pod.cpu <= self.cpu_capacity and
                self.memory_usage + pod.memory <= self.memory_capacity and
                self.disk_usage + pod.disk <= self.disk_capacity):
            # Alocar recursos
            self.cpu_usage += pod.cpu
            self.memory_usage += pod.memory
            self.disk_usage += pod.disk
            self.pods.append(pod)
            print(f"POD {pod.pod_id} alocado no Worker {self.worker_id}")
            return True
        else:
            print(f"POD {pod.pod_id} não pode ser alocado no Worker {self.worker_id}")
            return False

    # Método para simular o processamento contínuo de tarefas no Worker
    def process_tasks(self):
        while True:
            time.sleep(5)  # Simula o tempo de processamento de tarefas

            if self.pods:
                completed_pod = self.pods[0]
                print(f"Tarefas concluídas para POD {completed_pod.pod_id} no Worker {self.worker_id}")
                self.cpu_usage -= completed_pod.cpu
                self.memory_usage -= completed_pod.memory
                self.disk_usage -= completed_pod.disk
                self.pods.pop(0)  # Remove o POD concluído
                self.print_status()  # Imprime o status atual do Worker

                # Adiciona um novo POD à fila para ser processado
                new_pod = Pod(pod_id=completed_pod.pod_id + 100, cpu=2, memory=200, disk=50)
                self.work_queue.put(new_pod)
                print(f"Novo POD {new_pod.pod_id} adicionado à fila para processamento no Worker {self.worker_id}")

    # Método para imprimir o status atual do Worker
    def print_status(self):
        print(f"Worker {self.worker_id} - CPU: {self.cpu_usage}/{self.cpu_capacity}, "
              f"Memory: {self.memory_usage}/{self.memory_capacity}, "
              f"Disk: {self.disk_usage}/{self.disk_capacity}, "
              f"Pods: {len(self.pods)}")

# Definição da classe Master que coordena a alocação de PODs nos Workers
class Master:
    def __init__(self, workers):
        self.workers = workers

    # Método para agendar a alocação de PODs nos Workers
    def schedule_pods(self, pod_queue):
        while True:
            pod = pod_queue.get()
            if pod is None:
                break  # Encerra a execução ao receber um marcador de encerramento
            allocated = False
            for worker in self.workers:
                if worker.allocate_resources(pod):
                    allocated = True
                    break
            if not allocated:
                print(f"POD {pod.pod_id} não pôde ser alocado em nenhum Worker")
            self.print_cluster_status()
            time.sleep(0.5)

    # Método para imprimir o status atual do cluster
    def print_cluster_status(self):
        print("\nStatus do Cluster:")
        for worker in self.workers:
            worker.print_status()

# Função que simula a produção contínua de PODs
def producer(queue):
    i = 0
    while True:
        pod = Pod(pod_id=i, cpu=i % 3 + 1, memory=(i % 3 + 1) * 100, disk=50)
        queue.put(pod)
        print(f"POD {pod.pod_id} criado e adicionado à fila")
        time.sleep(1)
        i += 1

# Função principal
def main():
    num_workers = 2
    work_queue = queue.Queue()
    # Criação de Workers com capacidades específicas
    workers = [Worker(i, cpu_capacity=5, memory_capacity=500, network_latency=2, disk_capacity=200, work_queue=work_queue) for i in range(num_workers)]
    master = Master(workers)

    producer_thread = threading.Thread(target=producer, args=(work_queue,))
    consumer_thread = threading.Thread(target=master.schedule_pods, args=(work_queue,))
    processing_threads = [threading.Thread(target=worker.process_tasks) for worker in workers]

    producer_thread.start()
    consumer_thread.start()
    for thread in processing_threads:
        thread.start()

    input("Pressione Enter para encerrar...")

    work_queue.put(None)
    producer_thread.join()
    consumer_thread.join()

    for worker in workers:
        work_queue.put(None)

    for thread in processing_threads:
        thread.join()

if __name__ == "__main__":
    main()
